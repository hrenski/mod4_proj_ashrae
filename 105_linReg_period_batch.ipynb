{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import correlate, hilbert\n",
    "import scipy.ndimage as nd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import get_scorer, make_scorer, r2_score, mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "from utilities import reduce_df_mem_usage, print_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set(\"dark_background\")\n",
    "#sns.set(context=\"talk\")\n",
    "gc.enable()\n",
    "\n",
    "sns.set(style=\"ticks\", context=\"talk\")\n",
    "plt.style.use(\"dark_background\")\n",
    "%matplotlib inline\n",
    "\n",
    "rand_seed = 1234\n",
    "rand_state = np.random.RandomState(rand_seed)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "PATH = '/home/dhren/Documents/000_flatiron/002_projects/006_1028_kaggle_ASHRAE/data'\n",
    "\n",
    "FIGSIZE = (28, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mega_est(mega_est, df, cols, stat = 'mean'):\n",
    "    \"\"\"stat = mean, median\"\"\"\n",
    "    y_pred = np.zeros((len(mega_est), len(df)), dtype = 'f4')\n",
    "\n",
    "    for i, est in enumerate(mega_est):\n",
    "        y_pred[i] = est.predict(df[cols])\n",
    "        \n",
    "    if stat == 'median':\n",
    "        y_pred = np.median(y_pred, axis = 0)\n",
    "    else:\n",
    "        y_pred = np.mean(y_pred, axis = 0)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_nojunk(x):\n",
    "    bol = pd.isna(x) | (x == 0)\n",
    "    return np.median(x[~bol])\n",
    "\n",
    "def junk(x):\n",
    "    bol = pd.isna(x) | (x == 0)\n",
    "    return bol\n",
    "\n",
    "\n",
    "def make_mods(x):\n",
    "    bid = x.building_id.unique()[0]\n",
    "    mid = x.meter.unique()[0]\n",
    "    \n",
    "    m_min, m_max = x.meter_reading.min(), x.meter_reading.max()\n",
    "\n",
    "    encode = RobustScaler()\n",
    "    lr = BaggingRegressor(base_estimator = LinearRegression(), n_estimators = 10, random_state = rand_state)\n",
    "    clipped_lr = TransformedTargetRegressor(regressor=lr, inverse_func = lambda x : np.clip(x, m_min, m_max), check_inverse=True)\n",
    "    #lr = LinearRegression()\n",
    "    pipe = make_pipeline(encode, clipped_lr)\n",
    "\n",
    "    scores = cross_validate(pipe, x[[\"pred_week\", \"pred_dayofweek\", \"pred_hourofday\"]], x[\"meter_reading\"], cv = 5, n_jobs = -1, scoring = {'log_mse' : log_mse, 'r2' : get_scorer('r2'), 'mae' : mae}, return_estimator = True, return_train_score = True)\n",
    "\n",
    "    mods[(bid, mid)] = scores.pop('estimator')\n",
    "    \n",
    "    x['Prediction'] = apply_mega_est(mods[(bid, mid)], x, [\"pred_week\", \"pred_dayofweek\", \"pred_hourofday\"], stat = 'median')\n",
    "    \n",
    "    return x\n",
    "\n",
    "def apply_mods(x):\n",
    "    if len(x) == 0:\n",
    "        display(x)\n",
    "        raise RuntimeError(\"Dataframe is empty.\")\n",
    "    bid = x.building_id.unique()[0]\n",
    "    mid = x.meter.unique()[0]\n",
    "    \n",
    "    try:\n",
    "        x = x.interpolate(method = 'nearest').bfill().ffill()  \n",
    "    except Exception as e:\n",
    "        print(\"=\" * 25, bid, mid)\n",
    "        raise e\n",
    "        \n",
    "    x['Prediction'] = apply_mega_est(mods[(bid, mid)], x, [\"pred_week\", \"pred_dayofweek\", \"pred_hourofday\"], stat = 'median')\n",
    "\n",
    "    return x\n",
    "\n",
    "log_mse = make_scorer(mean_squared_log_error)\n",
    "mae = make_scorer(mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============  1/10 ===============\n",
      "Mean Sqrd Log Error 0.13190043\n",
      "Mean Sqrd Log Error 0.11123194\n"
     ]
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "for i in [0]:\n",
    "    \n",
    "    print(\"{:s} {:2d}/{:2d} {:s}\".format(\"=\"*15, i+1, 10, \"=\"*15))\n",
    "\n",
    "    df_tmp = pd.read_csv(op.join(PATH, 'train_%02d.csv'%(i)))\n",
    "\n",
    "    df_tmp['timestamp'] = pd.to_datetime(df_tmp['timestamp'])\n",
    "    df_tmp['week'] = pd.Series(df_tmp.timestamp).dt.week.values\n",
    "    df_tmp['dayofweek'] = pd.Series(df_tmp.timestamp).dt.dayofweek.values\n",
    "    df_tmp['hourofday'] = pd.Series(df_tmp.timestamp).dt.hour.values\n",
    "\n",
    "    df_train = reduce_df_mem_usage(df_tmp)\n",
    "    del df_tmp; gc.collect()\n",
    "\n",
    "    group = ['building_id', 'meter']\n",
    "    target = 'meter_reading'\n",
    "\n",
    "    grp = df_train.groupby(group)[[target]]\n",
    "    idx = grp.transform(junk)\n",
    "    df_train.loc[idx.values.ravel(), target] = grp.transform(med_nojunk).loc[idx.values.ravel()]\n",
    "\n",
    "    del idx\n",
    "    gc.collect()\n",
    "\n",
    "    preds_week = reduce_df_mem_usage(df_train.groupby(['building_id', 'meter', 'week'])[[target]].median().rename({'meter_reading': 'pred_week'},axis=1))\n",
    "    preds_dayofweek = reduce_df_mem_usage(df_train.groupby(['building_id', 'meter', 'dayofweek'])[[target]].median().rename({'meter_reading': 'pred_dayofweek'},axis=1))\n",
    "    preds_hourofday = reduce_df_mem_usage(df_train.groupby(['building_id', 'meter', 'hourofday'])[[target]].median().rename({'meter_reading': 'pred_hourofday'},axis=1))\n",
    "\n",
    "    df_tmp = df_train.merge(preds_week, on=['building_id', 'meter', 'week'], how='left')\n",
    "    df_tmp = df_tmp.merge(preds_dayofweek, on=['building_id', 'meter', 'dayofweek'], how='left')\n",
    "    df_tmp = df_tmp.merge(preds_hourofday, on=['building_id', 'meter', 'hourofday'], how='left')\n",
    "\n",
    "    df_train = reduce_df_mem_usage(df_tmp)\n",
    "\n",
    "    del df_tmp\n",
    "    gc.collect()\n",
    "\n",
    "    mods = {}\n",
    "\n",
    "    df_train = df_train.groupby(['building_id', 'meter']).apply(make_mods)\n",
    "\n",
    "    print(\"Mean Sqrd Log Error\", mean_squared_log_error(df_train.meter_reading, df_train.pred_week))\n",
    "    print(\"Mean Sqrd Log Error\", mean_squared_log_error(df_train.meter_reading, df_train.Prediction))\n",
    "\n",
    "    del df_train\n",
    "    gc.collect()\n",
    "\n",
    "    df_tmp = pd.read_csv(op.join(PATH, 'test_%02d.csv'%(i)))\n",
    "\n",
    "    df_tmp['timestamp'] = pd.to_datetime(df_tmp['timestamp'])\n",
    "    df_tmp['week'] = pd.Series(df_tmp.timestamp).dt.week.values\n",
    "    df_tmp['dayofweek'] = pd.Series(df_tmp.timestamp).dt.dayofweek.values\n",
    "    df_tmp['hourofday'] = pd.Series(df_tmp.timestamp).dt.hour.values\n",
    "\n",
    "    df_test = reduce_df_mem_usage(df_tmp)\n",
    "\n",
    "    del df_tmp\n",
    "    gc.collect()\n",
    "\n",
    "    df_tmp = df_test.merge(preds_week, on=['building_id', 'meter', 'week'], how='left')\n",
    "    df_tmp = df_tmp.merge(preds_dayofweek, on=['building_id', 'meter', 'dayofweek'], how='left')\n",
    "    df_tmp = df_tmp.merge(preds_hourofday, on=['building_id', 'meter', 'hourofday'], how='left')\n",
    "\n",
    "    df_test = reduce_df_mem_usage(df_tmp)\n",
    "\n",
    "    del df_tmp\n",
    "    gc.collect()\n",
    "\n",
    "    df_test = df_test.groupby(['building_id', 'meter']).apply(apply_mods)\n",
    "    \n",
    "    df_test[['row_id', 'Prediction']].to_csv(op.join(PATH, 'submission_1029_periodic_linReg_%02d.csv'%(i)), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aha = df_test[(df_test.building_id == 0) & (df_test.meter == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_mega_est(mods[(0, 0)], aha, [\"pred_week\", \"pred_dayofweek\", \"pred_hourofday\"], stat = 'median').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aha.interpolate(method = 'nearest')#.bfill().ffill()\n",
    "\n",
    "aha.loc[0, 'pred_week'] = np.nan\n",
    "\n",
    "aha.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.read_csv(op.join(PATH, 'test_%02d.csv'%(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.groupby(['building_id', 'meter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "li = []\n",
    "\n",
    "for i in range(10):\n",
    "    li.append(pd.read_csv(op.join(PATH, 'submission_1029_periodic_linReg_%02d.csv'%(i))\n",
    "\n",
    "pd.concat(li, axis=0, ignore_index=True).to_csv(op.join(PATH, 'submission_1029_periodic_linReg.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
